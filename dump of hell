def main():
    """Enhanced example demonstrating all advanced features"""
    print("="*70)
    print("ðŸš€ HYDROPREDICT ELITE - Advanced Swim Performance Engine v2.0")
    print("="*70)
    
    # Initialize app with ensemble
    print("\nâš™ï¸ Initializing system with 5-model ensemble...")
    app = HydroPredictEliteApp(model_type='auto', n_ensemble=5)
    
    # Use provided swimmers_import.csv from repository instead of generating
    print("\nðŸ“ Using provided swimmers_import.csv in repository...")
    generated_sample = False
    sample_csv = str(Path(__file__).parent / 'swimmers_import.csv')
    
    # Load and train with event-specific models
    print("\nðŸŽ¯ Training with event-specific modeling...")
    profiles = app.load_and_train(sample_csv, use_event_specific=True)
    
    # Save model
    app.save_model("hydropredict_elite_model.pkl")
    
    # Analyze a specific athlete
    print("\nðŸ”¬ Generating comprehensive performance certificate...")
    test_athlete = profiles[0]
    certificate = app.analyze_athlete(test_athlete)
    
    # Print certificate
    app.report_generator.print_certificate(certificate)
    
    # Export to JSON
    app.export_report(certificate, f"{test_athlete.name}_certificate.json")
    
    # Batch analysis example
    print("\nðŸ“Š Batch analysis for all athletes...")
    all_certificates = app.batch_analyze(profiles[:5])  # First 5 athletes
    
    # Show summary statistics
    predicted_times = [c['performance_metrics']['predicted_time'] for c in all_certificates]
    uncertainties = [c['model_confidence']['prediction_uncertainty'] for c in all_certificates]
    
    print(f"\nðŸ“ˆ Batch Summary:")
    print(f"   Athletes analyzed: {len(all_certificates)}")
    print(f"   Mean predicted time: {np.mean(predicted_times):.2f}s")
    print(f"   Mean uncertainty: Â±{np.mean(uncertainties):.3f}s")
    
    # Demonstrate model loading
    print("\nðŸ”„ Demonstrating model persistence...")
    new_app = HydroPredictEliteApp()
    new_app.load_model("hydropredict_elite_model.pkl")
    
    # Verify loaded model works
    test_certificate = new_app.analyze_athlete(test_athlete)
    print(f"âœ… Loaded model prediction: {test_certificate['performance_metrics']['predicted_time']:.2f}s")
    
    # Cleanup (only remove if we generated a temporary sample file)
    if 'generated_sample' in locals() and generated_sample:
        os.unlink(sample_csv)
    
    print("\n" + "="*70)
    print("âœ… HydroPredict Elite demonstration complete!")
    print("="*70)


if __name__ == "__main__":
    main()









def main():
    """Enhanced example demonstrating all advanced features"""
    print("="*70)
    print("ðŸš€ HYDROPREDICT ELITE - Advanced Swim Performance Engine v2.0")
    print("="*70)
    
    # Initialize app with ensemble
    print("\nâš™ï¸ Initializing system with 5-model ensemble...")
    app = HydroPredictEliteApp(model_type='auto', n_ensemble=5)
    
    # Create enhanced sample data
    print("\nðŸ“ Creating enhanced sample dataset...")
    sample_csv = create_enhanced_sample_data()
    
    # Load and train with event-specific models
    print("\nðŸŽ¯ Training with event-specific modeling...")
    profiles = app.load_and_train(sample_csv, use_event_specific=True)
    
    # Save model
    app.save_model("hydropredict_elite_model.pkl")
    
    # Analyze a specific athlete
    print("\nðŸ”¬ Generating comprehensive performance certificate...")
    test_athlete = profiles[0]
    certificate = app.analyze_athlete(test_athlete)
    
    # Print certificate
    app.report_generator.print_certificate(certificate)
    
    # Export to JSON
    app.export_report(certificate, f"{test_athlete.name}_certificate.json")
    
    # Batch analysis example
    print("\nðŸ“Š Batch analysis for all athletes...")
    all_certificates = app.batch_analyze(profiles[:5])  # First 5 athletes
    
    # Show summary statistics
    predicted_times = [c['performance_metrics']['predicted_time'] for c in all_certificates]
    uncertainties = [c['model_confidence']['prediction_uncertainty'] for c in all_certificates]
    
    print(f"\nðŸ“ˆ Batch Summary:")
    print(f"   Athletes analyzed: {len(all_certificates)}")
    print(f"   Mean predicted time: {np.mean(predicted_times):.2f}s")
    print(f"   Mean uncertainty: Â±{np.mean(uncertainties):.3f}s")
    
    # Demonstrate model loading
    print("\nðŸ”„ Demonstrating model persistence...")
    new_app = HydroPredictEliteApp()
    new_app.load_model("hydropredict_elite_model.pkl")
    
    # Verify loaded model works
    test_certificate = new_app.analyze_athlete(test_athlete)
    print(f"âœ… Loaded model prediction: {test_certificate['performance_metrics']['predicted_time']:.2f}s")
    
    # Cleanup
    os.unlink(sample_csv)
    
    print("\n" + "="*70)
    print("âœ… HydroPredict Elite demonstration complete!")
    print("="*70)


if __name__ == "__main__":
    main()


























def create_enhanced_sample_data() -> str:
    """Create enhanced sample CSV with dynamic column prefixes"""
    import tempfile
    
    # Generate 50 sample athletes with realistic variation
    np.random.seed(42)
    n_samples = 50
    
    data = {
        'name': [f"Athlete_{i}" for i in range(n_samples)],
        'event': np.random.choice(
            ['50m Free', '100m Free', '200m Free', '400m Free', '200m IM'],
            n_samples
        ),
        'previous_best_time': np.random.normal(55, 5, n_samples),
        'target_time': np.random.normal(54, 5, n_samples),
        
        # Biometrics with bio_ prefix
        'bio_hrv': np.random.normal(65, 10, n_samples),
        'bio_resting_hr': np.random.normal(50, 5, n_samples),
        'bio_sleep_hours': np.random.normal(8, 1, n_samples),
        'bio_sleep_quality': np.random.normal(80, 10, n_samples),
        'bio_muscle_soreness': np.random.uniform(1, 10, n_samples),
        'bio_body_mass': np.random.normal(75, 8, n_samples),
        'bio_hydration_estimate': np.random.normal(95, 3, n_samples),
        'bio_blood_lactate': np.random.exponential(2, n_samples),
        
        # Environment with env_ prefix
        'env_water_temp': np.random.normal(27.5, 1, n_samples),
        'env_air_temp': np.random.normal(24, 2, n_samples),
        'env_humidity': np.random.normal(55, 10, n_samples),
        'env_pressure': np.random.normal(1013, 5, n_samples),
        'env_altitude': np.random.choice([0, 500, 1000], n_samples),
        'env_lane_number': np.random.randint(1, 9, n_samples),
        'env_pool_type': np.random.choice(['LCM', 'SCM', 'SCY'], n_samples),
        
        # Stroke metrics with stroke_ prefix
        'stroke_stroke_rate': np.random.normal(55, 8, n_samples),
        'stroke_stroke_length': np.random.normal(2.1, 0.3, n_samples),
        'stroke_distance_per_stroke': np.random.normal(2.0, 0.3, n_samples),
        'stroke_turn_time': np.random.normal(0.8, 0.2, n_samples),
        'stroke_underwater_distance': np.random.normal(12, 3, n_samples),
        'stroke_intra_cycle_velocity_fluctuation': np.random.exponential(0.15, n_samples),
        
        # Cognitive with cog_ prefix
        'cog_stress_level': np.random.uniform(1, 10, n_samples),
        'cog_screen_time': np.random.exponential(3, n_samples),
        'cog_gaming_hours': np.random.exponential(1, n_samples),
        'cog_focus_rating': np.random.uniform(1, 10, n_samples),
        'cog_pre_race_anxiety': np.random.uniform(1, 10, n_samples),
        
        # Training with train_ prefix
        'train_acute_load': np.random.normal(800, 200, n_samples),
        'train_chronic_load': np.random.normal(750, 150, n_samples),
        'train_weekly_yardage': np.random.normal(35000, 5000, n_samples),
        'train_training_stress_balance': np.random.normal(0, 3, n_samples)
    }
    
    df = pd.DataFrame(data)
    
    temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False)
    df.to_csv(temp_file.name, index=False)
    temp_file.close()
    
    return temp_file.name
